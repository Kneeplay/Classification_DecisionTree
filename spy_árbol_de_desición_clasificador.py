# -*- coding: utf-8 -*-
"""SPY - Árbol de desición clasificador

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14hNKw5NruPh5qd9151E7uVlQwmn5hvR7

**1- Carga de datos**

Carga de datos a partir de un fichero csv en Google Collaboratory:
"""

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

"""Carga de datos en un DataFrame con el nombre spy del dataset con una selección de variables. Visualizamos la cabecera y los primeros 4 registros:"""

import pandas as pd
import io
spy = pd.read_csv(io.StringIO(uploaded[fn].decode('utf-8')), sep=',', usecols=['CLASIFICADOR', '2', '42', '45','48','68','75','88','139','171','179','187','218','221','223','231','237', 'FECHA.month'])
spy.head()

"""Visualizamos el clasificador para comprobar si está balanceado o no:"""

import seaborn as sb

print("Distribución del clasificador:\n")
print(spy.groupby('CLASIFICADOR').size()) # Distribución del clasificador
print(sb.factorplot('CLASIFICADOR', data=spy, kind='count'))

"""El clasificador se encuentra claramente desbalanceado en una proporción 3,28 a 1 para el clasificador '1'

División de los datos en train y test:
"""

p_train = 0.75 # Porcentaje de train. Modificar para obtener diferentes conjuntos.

train = spy[:int((len(spy))*p_train)]
test = spy[int((len(spy))*p_train):]

print("Ejemplos usados para entrenar: ", len(train))
print("Ejemplos usados para test: ", len(test))
print("\n")

features = spy.columns[1:]
x_train = train[features]
y_train = train['CLASIFICADOR']

x_test = test[features]

"""Creación del Árbol de decisión sin el parámetro "*max_depth*" (lo calculamos después). Se balancea el árbol con el parámetro *class_weight* según la relación calculada antes:"""

from sklearn import tree

clf = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split = 65, 
                                  min_samples_leaf = 20, class_weight={0:3.28})

clf.fit(x_train, y_train) # Construcción del modelo

preds = clf.predict(x_test) # Test del modelo

"""Visualización del resultado obtenido:"""

from sklearn.metrics import classification_report
print("Árbol de decisión: \n" 
      +classification_report(y_true=test['CLASIFICADOR'], y_pred=preds))

# Matriz de confusión

print("Matriz de confusión:\n")
matriz = pd.crosstab(test['CLASIFICADOR'], preds, rownames=['actual'], colnames=['preds'])
print(matriz)

"""Cálculo del nivel de profundidad (max_depth) óptimo:"""

from sklearn.model_selection import KFold

cv = KFold(n_splits = 10, shuffle = False) # Número de folds que haremos
accuracies = list()
max_attributes = len(list(spy))
depth_range = range(1, max_attributes + 1)

# Testeo de la profundidad desde 1 a la cantidad de atributos + 1

for depth in depth_range:
    fold_accuracy = []
    tree_model = tree.DecisionTreeClassifier(criterion='entropy', 
                                             min_samples_split = 65, 
                                             min_samples_leaf = 20,
                                             max_depth = depth,
                                             class_weight={0:3.28})
    for train_fold, valid_fold in cv.split(spy):
        f_train = spy.loc[train_fold]
        f_valid = spy.loc[valid_fold]
        
        model = tree_model.fit( X = f_train.drop(['CLASIFICADOR'], axis=1), 
                               y = f_train['CLASIFICADOR'])
        valid_acc = model.score(X = f_valid.drop(['CLASIFICADOR'], axis=1), 
                                y = f_valid['CLASIFICADOR'])
        fold_accuracy.append(valid_acc)
        
    avg = sum(fold_accuracy)/len(fold_accuracy)
    accuracies.append(avg)

# Mostramos los resultados obtenidos

df = pd.DataFrame({'Max depth': depth_range, 'Average Accuracy': accuracies})
df = df[['Max depth', 'Average Accuracy']]
print(df.to_string(index=False))

"""Creación del modelo de Árbol de Decisión con profundidad = 2 (*max_depth* óptimo)"""

clf = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split = 65, 
                                  min_samples_leaf = 20, max_depth = 2, 
                                  class_weight={0:3.28})

clf.fit(x_train, y_train) # Construcción del modelo

preds = clf.predict(x_test) # Test del modelo

"""Visualización del resultado obtenido:"""

from sklearn.metrics import classification_report
print("Árbol de decisión: \n" 
      +classification_report(y_true=test['CLASIFICADOR'], y_pred=preds))

# Matriz de confusión

print("Matriz de confusión:\n")
matriz = pd.crosstab(test['CLASIFICADOR'], preds, rownames=['actual'], colnames=['preds'])
print(matriz)

"""Variables más relevantes:"""

print("Relevancia de variables:\n")
print(pd.DataFrame({'Indicador': features ,
              'Relevancia': clf.feature_importances_}),"\n")
print("Máxima relevancia DF :" , max(clf.feature_importances_), "\n")

"""Visualización del Árbol de Decisión:"""

# https://pypi.python.org/pypi/pydot
!apt-get -qq install -y graphviz && pip install -q pydot
import pydot

from IPython.display import Image
from sklearn.externals.six import StringIO

dot_data = StringIO()
#tree.export_graphviz(clf, out_file=dot_data, feature_names=list(spy.drop(['CLASIFICADOR'], axis=1)))
tree.export_graphviz(clf, out_file = dot_data, proportion = True,
                     feature_names=list(spy.drop(['CLASIFICADOR'], axis=1)), 
                     class_names = ['0','1'], rounded = True, filled = True)

graph = pydot.graph_from_dot_data(dot_data.getvalue())
Image(graph[0].create_png())

"""Repetimos el algoritmo esta vez seleccionando sólo las variables que el Árbol de Decisión ha tomado como relevantes:"""

spy = pd.read_csv(io.StringIO(uploaded[fn].decode('utf-8')), sep=',', usecols=['CLASIFICADOR', '45','75','171'])
spy.head()

"""Histograma de las variables:"""

print("Histogramas de las variables seleccionadas:\n")
sb.distplot(spy['45'])
sb.distplot(spy['75'])
sb.distplot(spy['171'])

"""DIvisión del dataset en train y test:"""

p_train = 0.75 # Porcentaje de train. Modificar para obtener diferentes conjuntos.

train = spy[:int((len(spy))*p_train)]
test = spy[int((len(spy))*p_train):]

print("Ejemplos usados para entrenar: ", len(train))
print("Ejemplos usados para test: ", len(test))
print("\n")

features = spy.columns[1:]
x_train = train[features]
y_train = train['CLASIFICADOR']

x_test = test[features]

"""Cálculo del nivel de profundidad (max_depth) óptimo:"""

from sklearn.model_selection import KFold

cv = KFold(n_splits = 10, shuffle = False) # Número de folds que haremos
accuracies = list()
max_attributes = len(list(spy))
depth_range = range(1, max_attributes + 1)

# Testeo de la profundidad desde 1 a la cantidad de atributos + 1

for depth in depth_range:
    fold_accuracy = []
    tree_model = tree.DecisionTreeClassifier(criterion='entropy', 
                                             min_samples_split = 65, 
                                             min_samples_leaf = 20,
                                             max_depth = depth,
                                             class_weight={0:3.28})
    for train_fold, valid_fold in cv.split(spy):
        f_train = spy.loc[train_fold]
        f_valid = spy.loc[valid_fold]
        
        model = tree_model.fit( X = f_train.drop(['CLASIFICADOR'], axis=1), 
                               y = f_train['CLASIFICADOR'])
        valid_acc = model.score(X = f_valid.drop(['CLASIFICADOR'], axis=1), 
                                y = f_valid['CLASIFICADOR'])
        fold_accuracy.append(valid_acc)
        
    avg = sum(fold_accuracy)/len(fold_accuracy)
    accuracies.append(avg)

# Mostramos los resultados obtenidos

df = pd.DataFrame({'Max depth': depth_range, 'Average Accuracy': accuracies})
df = df[['Max depth', 'Average Accuracy']]
print(df.to_string(index=False))

"""Creación del modelo de Árbol de Decisión con profundidad = 4 (max_depth óptimo para el dataset con reducción de variables)"""

clf = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split = 65, 
                                  min_samples_leaf = 20, max_depth = 4, 
                                  class_weight={0:3.28})

clf.fit(x_train, y_train) # Construcción del modelo

preds = clf.predict(x_test) # Test del modelo

"""Visualización del resultado obtenido:"""

from sklearn.metrics import classification_report
print("Árbol de decisión: \n" 
      +classification_report(y_true=test['CLASIFICADOR'], y_pred=preds))

# Matriz de confusión

print("Matriz de confusión:\n")
matriz = pd.crosstab(test['CLASIFICADOR'], preds, rownames=['actual'], colnames=['preds'])
print(matriz)

"""Hemos obtenido un poco menos de precisión de la clase positiva pero más "aciertos" (True Positives) en la matriz de confusión.

Relevancia de las variables:
"""

print("Relevancia de variables:\n")
print(pd.DataFrame({'Indicador': features ,
              'Relevancia': clf.feature_importances_}),"\n")
print("Máxima relevancia DF :" , max(clf.feature_importances_), "\n")

"""Visualización del árbol:"""

from IPython.display import Image
from sklearn.externals.six import StringIO

dot_data = StringIO()
#tree.export_graphviz(clf, out_file=dot_data, feature_names=list(spy.drop(['CLASIFICADOR'], axis=1)))
tree.export_graphviz(clf, out_file = dot_data, proportion = True,
                     feature_names=list(spy.drop(['CLASIFICADOR'], axis=1)), 
                     class_names = ['0','1'], rounded = True, filled = True)

graph = pydot.graph_from_dot_data(dot_data.getvalue())
Image(graph[0].create_png())